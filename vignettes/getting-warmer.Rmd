---
title: "getting-warmer"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{getting-warmer}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  eval = greta:::check_tf_version("message"),
  cache = TRUE,
  comment = "#>"
)
knitr::opts_knit$set(global.par = TRUE)
set.seed(1)
```

```{r library}
library(greta)
library(greta.gp)
library(terra)
```

### More Gaussian processes in greta: now with a kernel for a sphere

So we know basically what `greta.gp` does ... what else can it do?

#### Example - a GP in 2D space

Let's extend the worked example in the `getting-started.Rmd` vignette to two dimensions. We're working in a flat plane - the response is now a function of Cartesian coordinates in two dimensions.

```{r simulate, message = FALSE}
# simulate data
x <- data.frame(lon = runif(20, 0, 10),
                lat = runif(20, 0, 10))
y <- sin(x$lon) + sin(x$lat) + rnorm(20, 3, 1)

plot(x, cex = y)

x_plot <- expand.grid(lon = seq(-1, 11, length.out = 200),
                      lat = seq(-1, 11, length.out = 200))
y_truth <- 2*sin(x_plot$lon) + 2*sin(x_plot$lat) + rnorm(200*200, 0, 0.5)
```

Let's use radial basis function (RBF) kernel on longitude and latitude. We provide the hyperparameters of the kernel (a lengthscale in each direction and a variance parameter) with their own priors. We also define a prior for the (what's the word?) - I'm pretty sure this guy (`obs_sd`) is our nugget variance.

```{r model, message = FALSE}
# hyperparameters
rbf_var <- lognormal(0, 1)
rbf_len <- lognormal(0, 1)
obs_sd <- lognormal(0, 1)

# kernel & GP
kernel <- rbf(rep(rbf_len, 2), rbf_var) + bias(1)
f <- gp(x, kernel)

# likelihood
distribution(y) <- normal(f, obs_sd)

# prediction
f_plot <- greta.gp::project(f, x_plot)
```

```{r fit, message = FALSE}
# fit the model by Hamiltonian Monte Carlo
m <- model(f_plot)
draws <- mcmc(m)

# r_hats <- coda::gelman.diag(draws,
#                             autoburnin = FALSE,
#                             multivariate = FALSE)
# summary(r_hats$psrf)
```

Take 200 samples from the posterior we approximated above and summarise them:

```{r plotting, fig.width = 10, fig.height = 6, dpi = 200}
# plot 200 posterior samples
par(mfrow=c(1,3))

plot(rast(cbind(x_plot, y_truth)), main="'truth'")
points(x, cex = y, col="white")

# summarise posterior samples
f_plot_draws <- calculate(f_plot, values = draws, nsim=200)
f_plot_est <- colMeans(f_plot_draws$f_plot[,,1])
f_plot_sd <- apply(f_plot_draws$f_plot[,,1], 2, sd)
f_plot_summ <- apply(f_plot_draws$f_plot[,,1], 2, summary)

plot(rast(cbind(x_plot, f_plot_est)), col = viridis(100), main="Mean posterior samples")
points(x, cex = y, col="white")

plot(rast(cbind(x_plot, f_plot_sd)), col = viridis(100), main="SD posterior samples")
points(x, cex = y, col="white")

```

The model's predictions are most different to the "truth" where the model has no data informing it. The posterior samples are most variable near extremes in the mean surface, where there is data.






