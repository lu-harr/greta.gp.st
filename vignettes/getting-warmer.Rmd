---
title: "getting-warmer"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{getting-warmer}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  eval = greta:::check_tf_version("message"),
  cache = TRUE,
  comment = "#>"
)
knitr::opts_knit$set(global.par = TRUE)
set.seed(1)
```

```{r library}
library(greta)
library(greta.gp)
library(terra)
```

### More Gaussian processes in greta: now with a kernel for a sphere

So we know basically what `greta.gp` does ... what else can it do?

#### Example - a GP in 2D space

Let's extend the worked example in the `getting-started.Rmd` vignette to two dimensions. We're working in a flat plane - the response is now a function of Cartesian coordinates in two dimensions.

```{r simulate, message = FALSE}
# simulate data
x <- data.frame(lon = runif(20, 0, 10),
                lat = runif(20, 0, 10))
y <- sin(x$lon) + sin(x$lat) + rnorm(20, 3, 1)

plot(x, cex = y)

x_plot <- expand.grid(lon = seq(-1, 11, length.out = 200),
                      lat = seq(-1, 11, length.out = 200))
y_truth <- 2*sin(x_plot$lon) + 2*sin(x_plot$lat) + rnorm(200*200, 0, 0.5)
```

Let's use radial basis function (RBF) kernel on longitude and latitude. We provide the hyperparameters of the kernel (a lengthscale in each direction and a variance parameter) with their own priors. We also define a prior for the (what's the word?) - I'm pretty sure this guy (`obs_sd`) is our nugget variance.

```{r model, message = FALSE}
# hyperparameters
rbf_var <- lognormal(0, 1)
rbf_len <- lognormal(0, 1)
obs_sd <- lognormal(0, 1)

# kernel & GP
kernel <- rbf(rep(rbf_len, 2), rbf_var) + bias(1)
f <- gp(x, kernel)

plot.kernel(kernel, dist_max = 11)

# likelihood
distribution(y) <- normal(f, obs_sd)

# prediction
f_plot <- greta.gp::project(f, x_plot)
```

```{r fit, message = FALSE}
# fit the model by Hamiltonian Monte Carlo
m <- model(f_plot)
draws <- mcmc(m)
```

Take 200 samples from the posterior we approximated above and summarise them:

```{r plotting, fig.width = 10, fig.height = 6, dpi = 200}
# plot 200 posterior samples
par(mfrow=c(1,3))

plot(rast(cbind(x_plot, y_truth)), main="'truth'")
points(x, cex = y, col="white")

# summarise posterior samples
f_plot_draws <- calculate(f_plot, values = draws, nsim=200)
f_plot_est <- colMeans(f_plot_draws$f_plot[,,1])
f_plot_sd <- apply(f_plot_draws$f_plot[,,1], 2, sd)
f_plot_summ <- apply(f_plot_draws$f_plot[,,1], 2, summary)

plot(rast(cbind(x_plot, f_plot_est)), col = viridis(100), main="Mean posterior samples")
points(x, cex = y, col="white")

plot(rast(cbind(x_plot, f_plot_sd)), col = viridis(100), main="SD posterior samples")
points(x, cex = y, col="white")

```

The model's predictions are most different to the "truth" where the model has no data informing it. The posterior samples are most variable near extremes in the mean surface, where there is data.

#### Example - a GP on a linear model (whatever it is we call that)

Pinching an example right out of the `greta` forum ...

```{r simulate, message = FALSE}
# simulate data
n <- 100
x <- cbind(temp = rnorm(n),
           rain = runif(10),
           time = seq_len(n),
           lat = runif(n),
           lon = runif(n))

# set component kernels
environmental <- bias(1) + linear(c(5, 5), columns = 1:2) 
temporal <- expo(100, 1, columns = 3)
spatial <- mat32(c(3, 3), 1, columns = c(4:5))
K <- environmental * temporal + spatial # combine the kernels
eta <- gp(x, K)

plot.kernel(environmental, 1)

# aren't we missing the actual model?

# pull out the separate components of this GP, by projecting it using only one 
# of the component kernels
eta_time <- greta.gp::project(eta, x, temporal)
eta_space <- greta.gp::project(eta, x, spatial)

# E.g. to fit a model (in this case just the prior) and plot just the temporal 
# effects (which gets multiplied by the environmental linear model) you would do:
m <- model(eta)
draws <- mcmc(m)

eta_time_draws <- calculate(eta_time, values=draws, nsim=100)
eta_sim <- drop(eta_time_draws$eta_time)[100, ]
plot(eta_sim ~ x[, "time"], type = "l") # Nick's line wiggles down

eta_space_draws <- calculate(eta_space, values=draws, nsim=100) # have I gotten both dimensions? idk?
eta_sim <- drop(eta_space_draws$eta_space)[100,]

beta_0 <- normal(0, 5)
sigma_e <- cauchy(0, 1, truncation = c(0, Inf))
sigma_u <- cauchy(0, 1, truncation = c(0, Inf))
lengthscale <- normal(0, 10, truncation = c(0, Inf))

k1 <- mat32(lengthscale, sigma_u ^ 2)
k2 <- bias(25)  # pass in the prior variance on beta_0 (5 ^ 2)
K <- k1 + k2
f_gp <- gp(pts, K, tol = 1e-6)
f <- f_gp  # + beta_0

distribution(y1) <- normal(f, sigma_e)

m1 <- model(lengthscale, sigma_u) # no beta_0 in here
draws1 <- mcmc(m1, one_by_one = TRUE)

```








